{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC45n3MTy0oh"
      },
      "source": [
        "# PA3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rMWL8FMlnY1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GYmaCdG01e5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "os.chdir('/content/drive/MyDrive/3_face_segmentation')\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwc_AaVOAmMs"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from model import SegNet\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "import tqdm\n",
        "from utils import *\n",
        "import cv2\n",
        "from torchvision.utils import save_image\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecOOwcwPAt5y"
      },
      "outputs": [],
      "source": [
        "class Dataset(object):\n",
        "    def __init__(self, img_path, label_path, method='train'):\n",
        "        self.img_path =  img_path\n",
        "        self.label_path = label_path\n",
        "        self.train_dataset = []\n",
        "        self.test_dataset = []\n",
        "        self.mode = method == 'train'\n",
        "        self.preprocess()\n",
        "        if self.mode:\n",
        "            self.num_images = len(self.train_dataset)\n",
        "        else:\n",
        "            self.num_images = len(self.test_dataset)\n",
        "\n",
        "    def preprocess(self):\n",
        "        if self.mode:\n",
        "            len = 4500\n",
        "        else:\n",
        "            len = 500\n",
        "        for i in range(len):\n",
        "            # 4500 넘어까지지 되는 문제로 수정\n",
        "            # len([name for name in os.listdir(self.img_path) if os.path.isfile(os.path.join(self.img_path, name))])):\n",
        "            img_path = os.path.join(self.img_path, str(i) + '.jpg')\n",
        "            label_path = os.path.join(self.label_path, str(i) + '.png')\n",
        "            if self.mode == True:\n",
        "                self.train_dataset.append([img_path, label_path])\n",
        "            else:\n",
        "                self.test_dataset.append([img_path, label_path])\n",
        "        print('Finished preprocessing the CelebA dataset...')\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        dataset = self.train_dataset if self.mode == True else self.test_dataset\n",
        "        img_path, label_path = dataset[index]\n",
        "        image = Image.open(img_path)\n",
        "        label = Image.open(label_path)\n",
        "        transform = torchvision.transforms.Compose(\n",
        "            [torchvision.transforms.ToTensor(), torchvision.transforms.Resize((512, 512))])\n",
        "        return transform(image), transform(label), img_path.split(\"/\")[-1]\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the number of images.\"\"\"\n",
        "        return self.num_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi01XP2TA0Dq"
      },
      "outputs": [],
      "source": [
        "class Tester(object):\n",
        "    def __init__(self, batch_size, epochs, lr):\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.learning_rate = lr\n",
        "        self.model = self.build_model()\n",
        "        # Load of pretrained_weight file\n",
        "        weight_PATH = \"finetuned_{}_{}_{}_softmax_onehot.pth\".format(self.epochs, self.batch_size, self.learning_rate)\n",
        "        # weight_PATH = 'pretrained_weight.pth'\n",
        "        self.model.load_state_dict(torch.load(weight_PATH))\n",
        "        dataset = Dataset(img_path=\"data/test_img\", label_path=\"data/test_label\", method='test')\n",
        "        self.dataloader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                                      batch_size=self.batch_size,\n",
        "                                                      shuffle=True,\n",
        "                                                      num_workers=2,\n",
        "                                                      drop_last=False)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        print(\"Testing...\")\n",
        "\n",
        "    def test(self):\n",
        "        make_folder(\"test_mask_{}_{}_{}_softmax_onehot\".format(self.epochs, self.batch_size, self.learning_rate), '')\n",
        "        make_folder(\"test_color_mask_{}_{}_{}_softmax_onehot\".format(self.epochs, self.batch_size, self.learning_rate), '')\n",
        "        self.model.eval()\n",
        "        self.test_loss = 0\n",
        "        for i, data in enumerate(self.dataloader):\n",
        "            imgs = data[0].cuda()\n",
        "            target = data[1].cuda()\n",
        "            labels_predict = self.model(imgs)\n",
        "            labels_predict_plain = generate_label_plain(labels_predict, 512)\n",
        "            labels_predict_color = generate_label(labels_predict, 512)\n",
        "            batch_size = labels_predict.size()[0]\n",
        "\n",
        "            labels_predict_SM = torch.nn.functional.softmax(labels_predict, dim=1)\n",
        "\n",
        "            # Generat GT\n",
        "            # one-hot\n",
        "            hair = target > 0.005 # 0.007843137718737125 -> 2 (hair)\n",
        "            face = target > 0.003\n",
        "            face2 = target < 0.005\n",
        "            face = face * face2 # 0.003921568859368563 -> 1 (face) \n",
        "            back = target == 0 # 0 -> 0 (bg)\n",
        "            gt = torch.concat([back, face, hair], dim = 1).float()\n",
        "\n",
        "\n",
        "            # index1\n",
        "            # hair = target > 0.005 # 0.007843137718737125 -> 2 (hair)\n",
        "            # face = target > 0.003\n",
        "            # gt = hair.long() + face.long()\n",
        "\n",
        "            # index2\n",
        "            # gt = target * 255\n",
        "\n",
        "            # gt = gt.type(torch.LongTensor).cuda()\n",
        "            # gt = gt.squeeze()\n",
        "\n",
        "            loss = self.criterion(labels_predict_SM, gt) \n",
        "            self.test_loss += loss.item()\n",
        "\n",
        "            for k in range(batch_size):\n",
        "                cv2.imwrite(os.path.join(\"test_mask_{}_{}_{}_softmax_onehot\".format(self.epochs, self.batch_size, self.learning_rate), data[2][k]), labels_predict_plain[k])\n",
        "                save_image(labels_predict_color[k], os.path.join(\"test_color_mask_{}_{}_{}_softmax_onehot\".format(self.epochs, self.batch_size, self.learning_rate), data[2][k]))\n",
        "        print(f\"{len(self.dataloader)}\")\n",
        "        epoch_loss = self.test_loss / len(self.dataloader)\n",
        "\n",
        "        print(f\"epoch_loss is {epoch_loss}\")\n",
        "\n",
        "    def build_model(self):\n",
        "        model = SegNet(3).cuda()\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oqgylk7A7-S"
      },
      "outputs": [],
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, epochs, batch_size, lr):\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.learning_rate = lr\n",
        "        self.model = self.build_model()\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), self.learning_rate)\n",
        "\n",
        "        dataset = Dataset(img_path=\"data/train_img\", label_path=\"data/train_label\", method='train')\n",
        "        self.dataloader = torch.utils.data.DataLoader(dataset=dataset,\n",
        "                                                      batch_size=self.batch_size,\n",
        "                                                      shuffle=True,\n",
        "                                                      num_workers=2,\n",
        "                                                      drop_last=False)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def train(self):\n",
        "        for epoch in tqdm.tqdm(range(self.epochs + 1)):\n",
        "            epochLoss = 0\n",
        "            self.model.train()\n",
        "            self.train_loss = 0\n",
        "            for batch_idx, data in enumerate(self.dataloader):\n",
        "                imgs = torch.autograd.Variable(data[0]).cuda()\n",
        "                target = torch.autograd.Variable(data[1]).cuda()\n",
        "\n",
        "                labels_predict = self.model(imgs)\n",
        "                labels_predict = torch.nn.functional.softmax(labels_predict, dim=1)\n",
        "\n",
        "                # Generat GT\n",
        "                # one-hot\n",
        "                hair = target > 0.005 # 0.007843137718737125 -> 2 (hair)\n",
        "                face = target > 0.003\n",
        "                face2 = target < 0.005\n",
        "                face = face * face2 # 0.003921568859368563 -> 1 (face) \n",
        "                back = target == 0 # 0 -> 0 (bg)\n",
        "                gt = torch.concat([back, face, hair], dim = 1).float()\n",
        "\n",
        "                # index1\n",
        "                # hair = target > 0.005 # 0.007843137718737125 -> 2 (hair)\n",
        "                # face = target > 0.003\n",
        "                # gt = hair.long() + face.long()\n",
        "\n",
        "                # index2\n",
        "                # gt = target * 255\n",
        "\n",
        "                # gt = gt.type(torch.LongTensor).cuda()\n",
        "                # gt = gt.squeeze()\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                loss = self.criterion(labels_predict, gt) \n",
        "                self.train_loss += loss.item()\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "\n",
        "                print(f\"Epoch {epoch}/{self.epochs} - Batch {batch_idx}/{len(self.dataloader)}\")\n",
        "\n",
        "            epoch_loss = self.train_loss / len(self.dataloader) \n",
        "\n",
        "            print(f\"Epoch {epoch}/{self.epochs}, loss is {epoch_loss}\")\n",
        "\n",
        "        train_path = \"finetuned_{}_{}_{}_softmax_onehot.pth\".format(self.epochs, self.batch_size, self.learning_rate)\n",
        "        torch.save(self.model.state_dict(), train_path)\n",
        "        print('Finish training.')\n",
        "        \n",
        "      \n",
        "\n",
        "    def build_model(self):\n",
        "        model = SegNet(3).cuda()\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NvvW-pYA4Mi"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "lr = 0.01\n",
        "batch_size = 32\n",
        "trainer = Trainer(epochs, batch_size, lr)\n",
        "trainer.train()\n",
        "tester = Tester(batch_size, epochs, lr)\n",
        "tester.test()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}